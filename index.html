<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>Whisper Dictation</title>
    <script src="https://unpkg.com/react@18/umd/react.development.js"></script>
    <script src="https://unpkg.com/react-dom@18/umd/react-dom.development.js"></script>
    <script src="https://unpkg.com/@babel/standalone/babel.min.js"></script>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body {
            margin: 0;
            padding: 0;
            background: transparent;
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
        }
        .glass-effect {
            backdrop-filter: blur(20px);
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid rgba(255, 255, 255, 0.2);
        }
    </style>
</head>
<body>
    <div id="root"></div>
    
    <script type="text/babel">
        const { useState, useEffect, useRef } = React;
        const { ipcRenderer } = require('electron');

        // Button Component
        const Button = ({ children, onClick, disabled, variant = "default", size = "default", className = "" }) => {
            const baseClasses = "inline-flex items-center justify-center rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-2 focus-visible:ring-ring focus-visible:ring-offset-2 disabled:opacity-50 disabled:pointer-events-none ring-offset-background";
            
            const variants = {
                default: "bg-primary text-primary-foreground hover:bg-primary/90 bg-slate-900 text-white hover:bg-slate-800",
                destructive: "bg-destructive text-destructive-foreground hover:bg-destructive/90 bg-red-500 text-white hover:bg-red-600",
                outline: "border border-input hover:bg-accent hover:text-accent-foreground border-slate-200 hover:bg-slate-100",
                secondary: "bg-secondary text-secondary-foreground hover:bg-secondary/80 bg-slate-100 text-slate-900 hover:bg-slate-200",
                ghost: "hover:bg-accent hover:text-accent-foreground hover:bg-slate-100",
                link: "underline-offset-4 hover:underline text-primary text-blue-600"
            };
            
            const sizes = {
                default: "h-10 py-2 px-4",
                sm: "h-9 px-3 rounded-md",
                lg: "h-11 px-8 rounded-md",
                icon: "h-10 w-10"
            };
            
            return (
                <button
                    className={`${baseClasses} ${variants[variant]} ${sizes[size]} ${className}`}
                    onClick={onClick}
                    disabled={disabled}
                >
                    {children}
                </button>
            );
        };

        // Card Components
        const Card = ({ children, className = "" }) => (
            <div className={`rounded-lg border bg-card text-card-foreground shadow-sm border-slate-200 bg-white ${className}`}>
                {children}
            </div>
        );

        const CardContent = ({ children, className = "" }) => (
            <div className={`p-6 pt-0 ${className}`}>
                {children}
            </div>
        );

        // Voice bar animation component (smaller bars)
        const VoiceBar = ({ active }) => {
            const [tick, setTick] = React.useState(0);
            React.useEffect(() => {
                if (!active) return;
                const interval = setInterval(() => setTick(t => t + 1), 40);
                return () => clearInterval(interval);
            }, [active]);
            return (
                <div style={{ display: 'flex', alignItems: 'flex-end', height: 10, gap: 1 }}>
                    {[...Array(10)].map((_, i) => {
                        const phase = (tick + i * 2) / 4;
                        const height = active ? (4 + 4 * (0.5 + 0.5 * Math.sin(phase))) : 4;
                        return (
                            <div
                                key={i}
                                style={{
                                    width: 2,
                                    height,
                                    background: 'white',
                                    borderRadius: 1,
                                    transition: 'height 0.15s',
                                    opacity: 0.95
                                }}
                            />
                        );
                    })}
                </div>
            );
        };

        // Main App Component
        const App = () => {
            const [isRecording, setIsRecording] = useState(false);
            const [isProcessing, setIsProcessing] = useState(false);
            const [transcript, setTranscript] = useState('');
            const [error, setError] = useState('');
            const mediaRecorderRef = useRef(null);
            const audioChunksRef = useRef([]);

            const startRecording = async () => {
                try {
                    console.log("Starting recording...")
                    setError('');
                    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                    console.log("Microphone access granted")
                    
                    mediaRecorderRef.current = new MediaRecorder(stream);
                    audioChunksRef.current = [];
                    
                    mediaRecorderRef.current.ondataavailable = (event) => {
                      console.log("Audio data chunk received, size:", event.data.size)
                      audioChunksRef.current.push(event.data);
                    };
                    
                    mediaRecorderRef.current.onstop = async () => {
                      console.log("Recording stopped, processing audio...")
                      const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/wav' });
                      await processAudio(audioBlob);
                      stream.getTracks().forEach(track => track.stop());
                    };
                    
                    mediaRecorderRef.current.start();
                    setIsRecording(true);
                    console.log("Recording started successfully")
                } catch (err) {
                    console.error("Recording error:", err)
                    setError('Failed to access microphone: ' + err.message);
                }
            };

            const stopRecording = () => {
                if (mediaRecorderRef.current && isRecording) {
                    mediaRecorderRef.current.stop();
                    setIsRecording(false);
                    setIsProcessing(true);
                }
            };

            const processAudio = async (audioBlob) => {
              try {
                console.log("Processing audio blob, size:", audioBlob.size)
                const formData = new FormData();
                formData.append('file', audioBlob, 'audio.wav');
                formData.append('model', 'whisper-1');

                // Get API key from window object (passed from main process)
                const apiKey = window.OPENAI_API_KEY;
                if (!apiKey) {
                  setError('OpenAI API key not found. Please check your .env file.');
                  setIsProcessing(false);
                  return;
                }

                console.log("Sending request to OpenAI Whisper API...")
                const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
                  method: 'POST',
                  headers: {
                    'Authorization': `Bearer ${apiKey}`
                  },
                  body: formData
                });

                console.log("Response status:", response.status)
                if (!response.ok) {
                  const errorText = await response.text()
                  console.error("API Error:", errorText)
                  throw new Error(`Failed to transcribe audio: ${response.status} ${errorText}`)
                }

                const result = await response.json();
                console.log("Transcription result:", result)
                const text = result.text.trim();
                
                if (text) {
                  setTranscript(text);
                  console.log("Transcribed text:", text)
                  // Automatically paste the text
                  await ipcRenderer.invoke('paste-text', text);
                } else {
                  console.log("No text transcribed")
                }
              } catch (err) {
                console.error("Transcription error:", err)
                setError('Transcription failed: ' + err.message);
              } finally {
                setIsProcessing(false);
              }
            };

            const handleClose = () => {
                ipcRenderer.invoke('hide-window');
            };

            useEffect(() => {
                let recording = false;
                const handleToggle = () => {
                    if (!recording && !isRecording && !isProcessing) {
                        startRecording();
                        recording = true;
                    } else if (isRecording) {
                        stopRecording();
                        recording = false;
                    }
                };
                ipcRenderer.on('toggle-dictation', handleToggle);
                return () => {
                    ipcRenderer.removeListener('toggle-dictation', handleToggle);
                };
            }, [isRecording, isProcessing]);

            // Remove spacebar logic for recording
            const handleKeyPress = (e) => {
                if (e.key === 'Escape') {
                    handleClose();
                }
            };
            useEffect(() => {
                document.addEventListener('keydown', handleKeyPress);
                return () => document.removeEventListener('keydown', handleKeyPress);
            }, []);

            // Minimal always-visible tab UI (no bars when idle)
            return (
                <div style={{
                    width: '100%',
                    height: '100%',
                    display: 'flex',
                    alignItems: 'center',
                    justifyContent: 'center',
                    pointerEvents: 'none',
                }}>
                    <div
                        className="glass-effect"
                        style={{
                            minWidth: 40,
                            minHeight: 8,
                            maxWidth: 40,
                            maxHeight: 8,
                            background: 'rgba(30,30,30,0.85)',
                            border: '1px solid #ccc',
                            borderRadius: 10,
                            boxShadow: '0 1px 6px rgba(0,0,0,0.10)',
                            display: 'flex',
                            alignItems: 'center',
                            justifyContent: 'center',
                            padding: '1px 6px',
                            pointerEvents: 'auto',
                        }}
                    >
                        {(isRecording || isProcessing) ? <VoiceBar active={true} /> : null}
                    </div>
                </div>
            );
        };

        ReactDOM.render(<App />, document.getElementById('root'));
    </script>
</body>
</html>
